{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITM 891 Project - Part 1\n",
    "## Web Scraping\n",
    "Scraping data of top 250 movies from IMDb website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import urllib\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting links of movies listed on \"Top Rated Movies\" page on IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining source page\n",
    "url_source = 'https://www.imdb.com/chart/top/?ref_=nv_mv_250'\n",
    "print(\"Source URL: \" + url_source)\n",
    "print()\n",
    "\n",
    "with urllib.request.urlopen(url_source) as url:\n",
    "    soup = bs4.BeautifulSoup(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Links of all the movies on the source page\n",
    "href_urls = set()\n",
    "for a_tag in soup.html.body.find_all('a'):\n",
    "    if 'href' in a_tag.attrs:\n",
    "        # Links to all the movies start with 'title'\n",
    "        if a_tag.attrs['href'].startswith('/title/'):\n",
    "            href_urls.add(a_tag.attrs['href'])\n",
    "            \n",
    "href_urls = list(href_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Links to movies on source page\n",
    "href_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining DataFrame to store information of movies listed on source page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Title', 'IMDB_Rating', 'Director','Star_1', 'Star_2', 'Star_3', 'Genre',\\\n",
    "           'Language', 'Release_Date', 'Budget', 'Gross_USA', 'Gross_Worldwide', 'Runtime_min']\n",
    "movie_df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data\n",
    "Extracting following attributes for each movie:\n",
    "* Title: Title of the movie\n",
    "* IMDB_Rating: IMDb Score for the movie\n",
    "* Director: Name of the movie director\n",
    "* Star_1, Star_2, Star_3: Names of lead actors of the movie\n",
    "* Genre: First genre listed on IMDb website\n",
    "* Language: Language in which the movie was released\n",
    "* Release_Date: Release date of the movie\n",
    "* Budget: Estimated budget of the movie\n",
    "* Gross_USA: Gross earning of the movie in USA\n",
    "* Gross_Worldwide: Gross worldwide earning of the movie\n",
    "* Runtime_min: Movie duration in minutes\n",
    "\n",
    "The following cell will take Approximately 200 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in href_urls:\n",
    "    a_url = urllib.parse.urljoin(url_source, link)\n",
    "    \n",
    "    with urllib.request.urlopen(a_url) as url:\n",
    "        soup = bs4.BeautifulSoup(url)\n",
    "    \n",
    "    title_div = soup.html.body.find_all('h1')\n",
    "    title = title_div[0].text\n",
    "    \n",
    "    rating_div = soup.findAll(\"span\", {\"itemprop\": \"ratingValue\"})\n",
    "    rating = float(rating_div[0].text)\n",
    "    \n",
    "    credit_div = soup.html.body.find_all('div', {\"class\": \"credit_summary_item\"})\n",
    "    for credit in credit_div:\n",
    "        if 'Director:' in credit.text:\n",
    "            director = credit.text.split('\\n')[-1]\n",
    "        if 'Stars:' in credit.text:\n",
    "            stars = s = credit.text.split('\\n')[2]\n",
    "            star1 = s.split(', ')[0]\n",
    "            star2 = s.split(', ')[1]\n",
    "            star3 = s.split(', ')[2][:-2]\n",
    "            \n",
    "    genre_div = soup.html.body.find_all('div', {\"class\": \"see-more inline canwrap\"})\n",
    "    for g_div in genre_div:\n",
    "        if 'Genres:' in g_div.text:\n",
    "            genre = g_div.text.split(\"\\n\")[2][:-2]\n",
    "    \n",
    "    details_div = soup.html.body.find_all('div', {\"class\": \"txt-block\"})\n",
    "    for detail in details_div:\n",
    "        if 'Language' in detail.text:\n",
    "            language = detail.text.split('\\n')[2]\n",
    "            \n",
    "        if 'Release Date' in detail.text:\n",
    "            release_info = detail.text.split(' ')\n",
    "            release_date = '-'.join(release_info[2:5])\n",
    "    \n",
    "        if 'Budget' in detail.text:\n",
    "            budget = detail.text.split('\\n')[1]\n",
    "            budget = int(''.join(re.findall('\\d', budget, flags = 0)))\n",
    "            \n",
    "        if 'Gross USA:' in detail.text:\n",
    "            gross_usa = detail.text.split('\\n')[1]\n",
    "            gross_usa = int(''.join(re.findall('\\d', gross_usa, flags = 0)))\n",
    "            \n",
    "        if 'Cumulative Worldwide Gross:' in detail.text:\n",
    "            gross = detail.text.split('\\n')[1]\n",
    "            gross = int(''.join(re.findall('\\d', gross, flags = 0)))\n",
    "        \n",
    "        if 'Runtime' in detail.text:\n",
    "            runtime = detail.text.split('\\n')[2]\n",
    "            runtime = int(runtime.split(' ')[0])\n",
    "            \n",
    "    movie = pd.DataFrame({'Title': title, 'IMDB_Rating': rating, 'Director': director,\\\n",
    "                          'Star_1': star1, 'Star_2': star2, 'Star_3': star3, 'Genre': genre,\\\n",
    "                          'Language': language, 'Release_Date': release_date, 'Budget': budget,\\\n",
    "                          'Gross_USA': gross_usa, 'Gross_Worldwide': gross, 'Runtime_min': runtime}, index = [0])\n",
    "    \n",
    "    movie_df = pd.concat([movie_df, movie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking DataFrame\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving DataFrame as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.to_csv('/Users/syedkashif9786/Documents/Michigan State University/Large Scale Data Analysis/imdb_data.csv',\\\n",
    "                index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
